


# Importing libraries 

import os
import base64
import requests
from dotenv import load_dotenv
import pandas as pd
import time
import matplotlib.pyplot as plt
from matplotlib.patches import Patch





# Loading spotify client ID and secret key from .env

load_dotenv()

client_id = os.getenv("SPOTIFY_CLIENT_ID")
client_secret = os.getenv("SPOTIFY_CLIENT_SECRET")

print("Client ID loaded:", client_id is not None)
print("Client Secret loaded:", client_secret is not None)





def get_spotify_token(client_id: str, client_secret: str) -> str:
    auth_string = f"{client_id}:{client_secret}"
    auth_bytes = auth_string.encode("utf-8")
    auth_b64 = base64.b64encode(auth_bytes).decode("utf-8")

    headers = {
        "Authorization": f"Basic {auth_b64}",
        "Content-Type": "application/x-www-form-urlencoded",}

    data = {"grant_type": "client_credentials"}

    r = requests.post(
        "https://accounts.spotify.com/api/token",
        headers=headers,
        data=data,
        timeout=15)
    r.raise_for_status()

    return r.json()["access_token"]


# Checking and showing first 20 chars

token = get_spotify_token(client_id, client_secret)
token[:10]





def get_artist(artist_id: str, token: str):
    headers = {"Authorization": f"Bearer {token}"}
    url = f"https://api.spotify.com/v1/artists/{artist_id}"
    r = requests.get(url, headers=headers, timeout=15)
    r.raise_for_status()
    return r.json()

TS_ID = "06HL4z0CvFAxyc27GXpf02"  # Taylor Swift
artist_data = get_artist(TS_ID, token)

print(f"Artist: {artist_data['name']}")
print(f"Followers: {artist_data['followers']['total']:,}")
print(f"Popularity: {artist_data['popularity']}")





load_dotenv()

nyt_api_key = os.getenv("NYT_API_KEY")
client_secret = os.getenv("NYT_CLIENT_SECRET")

def mask(s):
    if not s:
        return None
    return s[:4] + "..." + s[-4:]

print("NYT_API_KEY loaded:", nyt_api_key is not None)
print("NYT Client Secret loaded:", client_secret is not None)





NYT_BASE_URL = "https://api.nytimes.com/svc/search/v2/articlesearch.json"

def search_nyt_taylor_swift(api_key: str, page: int = 0):
    params = {
        "q": "Taylor Swift",
        "api-key": api_key,
        "page": page,}
    r = requests.get(NYT_BASE_URL, params=params, timeout=15)
    r.raise_for_status()
    return r.json()


nyt_data = search_nyt_taylor_swift(nyt_api_key, page=0)
print("Response type:", type(nyt_data))
print("Keys:", nyt_data.keys())


# Showing first TS article 

first = docs[0]
print(f"Headline: {first['headline']['main']}")
print(f"Date: {first['pub_date']}")
print(f"Section: {first.get('section_name', 'N/A')}")





# Extracting recent Taylor Swift-related articles 

print("Recent Taylor Swift articles:\n")
for i, d in enumerate(docs[:5], 1):
    print(f"{i}. {d['pub_date'][:10]} – {d['headline']['main']}")








from ts_media_bridge import SpotifyClient

sp = SpotifyClient()
ts = sp.get_artist("06HL4z0CvFAxyc27GXpf02")

print(f"Artist: {ts['name']}")
print(f"Followers: {ts['followers']['total']:,}")
print(f"Popularity: {ts['popularity']}")





df_albums = sp.get_artist_albums_df("06HL4z0CvFAxyc27GXpf02")

print(f"Total albums: {len(df_albums)}")
print(f"\nColumns: {df_albums.columns.tolist()}")
print(f"\nSample albums:")
print(df_albums[['name', 'release_date', 'popularity', 'is_rerecording']].head(10))





from ts_media_bridge import NYTClient

nyt = NYTClient()

# Searching for Taylor Swift articles
articles = nyt.search_taylor_swift(pages=3)
print(f"Retrieved {len(articles)} articles")

# Converting to DataFrame
df_articles = nyt.docs_to_df(articles)
print(f"\nDataFrame shape: {df_articles.shape}")
print(f"Columns: {df_articles.columns.tolist()}")








from ts_media_bridge import SpotifyClient, NYTClient, match_articles_to_albums

sp = SpotifyClient()
nyt = NYTClient()
TS_ID = "06HL4z0CvFAxyc27GXpf02"

# Getting albums
df_albums = sp.get_artist_albums_df(TS_ID)
print(f"Found {len(df_albums)} albums\n")

# Step 2: Collecting articles strategically
## Making fewer, targeted requests
print("Collecting NYT articles")
print("=" * 60)

all_docs = []

# Strategy A: Getting recent articles (most relevant)
print("\n1. Fetching recent articles (2023-present)...")
recent_docs = nyt.search_taylor_swift(pages=5, begin_date="20230101")
all_docs.extend(recent_docs)
print(f"   Found {len(recent_docs)} recent articles")
time.sleep(2)  # safety pause

# Strategy B: Getting folklore/evermore era (2020-2021)
print("\n2. Fetching folklore/evermore era (2020-2021)...")
folklore_docs = nyt.search_taylor_swift(pages=3, begin_date="20200101", end_date="20211231")
all_docs.extend(folklore_docs)
print(f"   Found {len(folklore_docs)} articles from 2020-2021")
time.sleep(2)

# Strategy C: Getting 1989/reputation era (2014-2018)
print("\n3. Fetching 1989/reputation era (2014-2018)...")
rep_docs = nyt.search_taylor_swift(pages=3, begin_date="20140101", end_date="20181231")
all_docs.extend(rep_docs)
print(f"   Found {len(rep_docs)} articles from 2014-2018")
time.sleep(2)

# Strategy D: Getting early career (2008-2013)
print("\n4. Fetching early career (2008-2013)...")
early_docs = nyt.search_taylor_swift(pages=2, begin_date="20080101", end_date="20131231")
all_docs.extend(early_docs)
print(f"   Found {len(early_docs)} articles from 2008-2013")

# Converting to df
df_articles = nyt.docs_to_df(all_docs)
df_articles = df_articles.drop_duplicates(subset=['web_url'])
print(f"\nTotal unique articles: {len(df_articles)}")

# Step 3: Matching to albums
print("\nMatching articles to albums...")
df_matched = match_articles_to_albums(df_albums, df_articles)
print(f"Matched {len(df_matched)} article-album pairs\n")

# Step 4: Analyzing results
mentions = (
    df_matched.groupby("album_base_title")["web_url"]
    .nunique()
    .reset_index(name="nyt_article_count")
    .sort_values("nyt_article_count", ascending=False))

print("=" * 60)
print("NYT Article Mentions by Album:")
print("=" * 60)
print(mentions.to_string(index=False))

# Step 5: Merging with Spotify data
df_albums_basic = df_albums[['base_title', 'release_date', 'popularity', 
                              'is_rerecording']].drop_duplicates(subset=['base_title'])

df_analysis = df_albums_basic.merge(
    mentions,
    left_on='base_title',
    right_on='album_base_title',
    how='left')
df_analysis['nyt_article_count'] = df_analysis['nyt_article_count'].fillna(0).astype(int)

print("\n" + "=" * 60)
print("Albums with Spotify Popularity vs NYT Coverage:")
print("=" * 60)
print(df_analysis[['base_title', 'release_date', 'popularity', 
                   'nyt_article_count']].to_string(index=False))

# Step 6: Displaying some matches
print("\n" + "=" * 60)
print("Sample Article-Album Matches:")
print("=" * 60)
for album in df_matched['album_base_title'].unique()[:5]:
    album_matches = df_matched[df_matched['album_base_title'] == album]
    print(f"\n{album} ({len(album_matches)} mentions):")
    for _, match in album_matches.head(2).iterrows():
        print(f"  • {match['headline'][:80]}...")
        print(f"    Published: {match['pub_date'][:10]}")

# Step 7: Saving results
print("\n" + "=" * 60)
df_matched.to_csv('album_article_matches.csv', index=False)
df_analysis.to_csv('album_analysis.csv', index=False)
df_articles.to_csv('nyt_articles.csv', index=False)
print("Saved:")
print("album_article_matches.csv")
print("album_analysis.csv")
print("nyt_articles.csv")





# Loading saved files 
df_saved_analysis = pd.read_csv('album_analysis.csv')
df_saved_matches = pd.read_csv('album_article_matches.csv')

print("Saved Analysis File:")
print(df_saved_analysis.head())
print(f"\nShape: {df_saved_analysis.shape}")
print(f"Columns: {df_saved_analysis.columns.tolist()}")

print("\nSaved Matches File:")
print(df_saved_matches.head())
print(f"\nShape: {df_saved_matches.shape}")
print(f"Columns: {df_saved_matches.columns.tolist()}")

# Creating a combined dataset including ALL Spotify metadata + NYT coverage
df_final = df_albums[['id', 'name', 'base_title', 'album_type', 'total_tracks', 
                      'release_date', 'popularity', 'label', 'is_rerecording', 
                      'is_deluxe']].drop_duplicates(subset=['base_title'])

# Adding NYT article counts
mentions = (
    df_matched.groupby("album_base_title")["web_url"]
    .nunique()
    .reset_index(name="nyt_article_count"))

# Fixing combined dataset 
df_final = df_albums[['id', 'name', 'base_title', 'album_type', 'total_tracks', 
                      'release_date', 'popularity', 'label', 'is_rerecording', 
                      'is_deluxe']].drop_duplicates(subset=['base_title'])

df_final = df_final.merge(
    mentions,
    left_on='base_title',
    right_on='album_base_title',
    how='left')

# Dropping redundant column and filling NaNs
df_final = df_final.drop(columns=['album_base_title'])  
df_final['nyt_article_count'] = df_final['nyt_article_count'].fillna(0).astype(int)

# Adding year for analysis
df_final['release_year'] = pd.to_datetime(df_final['release_date']).dt.year

# Sorting by release date
df_final = df_final.sort_values('release_date').reset_index(drop=True)

print("--CLEANED FINAL COMBINED DATASET--")
print(df_final)

# Saving cleaned version
df_final.to_csv('taylor_swift_combined_analysis.csv', index=False)
print("\n Saved cleaned version to: taylor_swift_combined_analysis.csv")





# Summary

print(f"Total albums: {len(df_final)}")
print(f"Albums with NYT coverage: {(df_final['nyt_article_count'] > 0).sum()}")
print(f"Total NYT articles matched: {df_final['nyt_article_count'].sum()}")
print(f"\nAlbums by NYT coverage:")
print(df_final[['base_title', 'release_year', 'popularity', 'nyt_article_count']].to_string(index=False))





ts_albums = df_final[[
    'id', 'name', 'base_title', 'release_date', 'release_year',
    'album_type', 'total_tracks', 'popularity', 'label',
    'is_rerecording', 'is_deluxe', 'nyt_article_count'
]].copy()

print("Taylor Swift Canonical Albums Dataset: ")
print(ts_albums)

# Saving
ts_albums.to_csv('ts_albums.csv', index=False)
print("Saved: ts_albums.csv")





# Visualization 1: NYT Coverage by Album

fig, ax = plt.subplots(figsize=(10, 4))

albums_with_coverage = df_final[df_final['nyt_article_count'] > 0].sort_values('nyt_article_count', ascending=True)

ax.barh(albums_with_coverage['base_title'], albums_with_coverage['nyt_article_count'], color='steelblue')
ax.set_xlabel('Number of NYT Articles', fontsize=12)
ax.set_ylabel('Album', fontsize=12)
ax.set_title('NYT Article Coverage by Taylor Swift Album', fontsize=14, fontweight='bold')
ax.grid(axis='x', alpha=0.3)

plt.tight_layout()
plt.savefig('nyt_coverage_by_album.png', dpi=300, bbox_inches='tight')
plt.show()


# Visualization 2: Spotify Popularity vs NYT Coverage

fig, ax = plt.subplots(figsize=(9, 5))

# Scatter plot
scatter = ax.scatter(
    df_final['popularity'], 
    df_final['nyt_article_count'],
    s=100,
    alpha=0.6,
    c=df_final['is_rerecording'].map({True: 'orange', False: 'steelblue'}),
    edgecolors='black',
    linewidth=0.5)

# Adding labels for albums with coverage
for _, row in df_final[df_final['nyt_article_count'] > 0].iterrows():
    ax.annotate(
        row['base_title'],
        (row['popularity'], row['nyt_article_count']),
        xytext=(5, 5),
        textcoords='offset points',
        fontsize=8,
        alpha=0.7)

ax.set_xlabel('Spotify Popularity Score', fontsize=12)
ax.set_ylabel('Number of NYT Articles', fontsize=12)
ax.set_title('Spotify Popularity vs NYT Coverage', fontsize=14, fontweight='bold')
ax.grid(True, alpha=0.3)

# Adding legend
legend_elements = [
    Patch(facecolor='steelblue', label='Original Albums'),
    Patch(facecolor='orange', label="Taylor's Versions")]
ax.legend(handles=legend_elements, loc='upper left')

plt.tight_layout()
plt.savefig('spotify_vs_nyt_coverage.png', dpi=300, bbox_inches='tight')
plt.show()
